{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "url = \"****\"\n",
    "api_key = \"****\"  \n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"User-Agent\": \"Apifox/1.0.0 (https://apifox.com)\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "input_json = \"entity_matching_FZ.json\"\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "task_prefix = data[\"task_prefix\"]\n",
    "examples = data[\"examples\"]\n",
    "\n",
    "prompts = []\n",
    "truth_labels = []\n",
    "for example in examples:\n",
    "    input_text = example[\"input\"]\n",
    "    target = example[\"target_scores\"]\n",
    "\n",
    "    prompt = f\"{task_prefix}{input_text}\"\n",
    "    prompts.append(prompt)\n",
    "\n",
    "    truth_labels.append(1 if target[\"Yes\"] == 1 else 0)\n",
    "\n",
    "predictions = []\n",
    "answers = []\n",
    "start_time = time.time()\n",
    "for i, prompt in enumerate(prompts):\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            generated_text = result['choices'][0]['message']['content'].strip()\n",
    "            answers.append(generated_text)\n",
    "\n",
    "            processed_pred = generated_text.lower().translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "\n",
    "            if \"yes\" in processed_pred:\n",
    "                predictions.append(1)\n",
    "            elif \"no\" in processed_pred:\n",
    "                predictions.append(0)\n",
    "            else:\n",
    "                predictions.append(0) \n",
    "\n",
    "        else:\n",
    "            print(f\"Error: Received status code {response.status_code}\")\n",
    "            answers.append(\"error\")\n",
    "            predictions.append(0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {str(e)}\")\n",
    "        answers.append(\"error\")\n",
    "        predictions.append(0)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "precision = precision_score(truth_labels, predictions, zero_division=1)\n",
    "recall = recall_score(truth_labels, predictions, zero_division=1)\n",
    "f1 = f1_score(truth_labels, predictions, zero_division=1)\n",
    "accuracy = accuracy_score(truth_labels, predictions)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"⏳ API Call {i+1}/{len(prompts)} took {elapsed_time:.2f} seconds\")\n",
    "\n",
    "results = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1,\n",
    "}\n",
    "\n",
    "output_dir = \"output_results-gpt4\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{output_dir}/results.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile, indent=2)\n",
    "\n",
    "with open(f\"{output_dir}/answers.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(answers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f\"{output_dir}/prompts.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(prompts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "url = \"****\"\n",
    "api_key = \"****\" \n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"User-Agent\": \"Apifox/1.0.0 (https://apifox.com)\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "input_json = \"FZ_fewshot.json\"\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "task_prefix = data[\"task_prefix\"]\n",
    "examples = data[\"examples\"]\n",
    "\n",
    "prompts = []\n",
    "truth_labels = []\n",
    "for example in examples:\n",
    "    input_text = example[\"input\"]\n",
    "    target = example[\"target_scores\"]\n",
    "\n",
    "    prompt = f\"{task_prefix}{input_text}\"\n",
    "    prompts.append(prompt)\n",
    "\n",
    "    truth_labels.append(1 if target[\"Yes\"] == 1 else 0)\n",
    "\n",
    "predictions = []\n",
    "answers = []\n",
    "start_time = time.time()\n",
    "for i, prompt in enumerate(prompts):\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            generated_text = result['choices'][0]['message']['content'].strip()\n",
    "            answers.append(generated_text)\n",
    "\n",
    "            processed_pred = generated_text.lower().translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "\n",
    "            if \"yes\" in processed_pred:\n",
    "                predictions.append(1)\n",
    "            elif \"no\" in processed_pred:\n",
    "                predictions.append(0)\n",
    "            else:\n",
    "                predictions.append(0)  \n",
    "\n",
    "        else:\n",
    "            print(f\"Error: Received status code {response.status_code}\")\n",
    "            answers.append(\"error\")\n",
    "            predictions.append(0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {str(e)}\")\n",
    "        answers.append(\"error\")\n",
    "        predictions.append(0)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "precision = precision_score(truth_labels, predictions, zero_division=1)\n",
    "recall = recall_score(truth_labels, predictions, zero_division=1)\n",
    "f1 = f1_score(truth_labels, predictions, zero_division=1)\n",
    "accuracy = accuracy_score(truth_labels, predictions)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"⏳ API Call {i+1}/{len(prompts)} took {elapsed_time:.2f} seconds\")\n",
    "\n",
    "results = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1,\n",
    "}\n",
    "\n",
    "output_dir = \"output_results-gpt4\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{output_dir}/results_FZ_fewshot.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile, indent=2)\n",
    "\n",
    "with open(f\"{output_dir}/answers_FZ_fewshot.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(answers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f\"{output_dir}/prompts_FZ_fewshot.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(prompts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdf39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import string\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "url = \"****\"\n",
    "api_key = \"****\"  \n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"User-Agent\": \"Apifox/1.0.0 (https://apifox.com)\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "input_json = \"entity_matching_FZ.json\"\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "task_prefix = data[\"task_prefix\"]\n",
    "examples = data[\"examples\"]\n",
    "\n",
    "all_prompts = []\n",
    "truth_labels = []\n",
    "for example in examples:\n",
    "    input_text = example[\"input\"]\n",
    "    target = example[\"target_scores\"]\n",
    "\n",
    "    prompts = [\n",
    "        f\"{task_prefix}{input_text}\",  \n",
    "        f\"{task_prefix} Compare the restaurant names and verify if they match exactly:\\n{input_text}\",  # Round 2: Emphasize name matching\n",
    "        f\"{task_prefix} Check the addresses and phone numbers for consistency in entity matching:\\n{input_text}\",  # Round 3: Emphasize address and phone matching\n",
    "        f\"{task_prefix} Compare the cuisines and other attributes for entity resolution:\\n{input_text}\",  # Round 4: Emphasize attribute matching\n",
    "        f\"{task_prefix} Evaluate all available information (name, address, phone, cuisine) to make a final decision:\\n{input_text}\",  # Round 5: Comprehensive matching\n",
    "    ]\n",
    "    all_prompts.append(prompts)\n",
    "\n",
    "    truth_labels.append(1 if target[\"Yes\"] == 1 else 0)\n",
    "\n",
    "predictions = []\n",
    "answers = []\n",
    "\n",
    "start_time = time.time()\n",
    "total_api_time = 0\n",
    "\n",
    "for i, prompts in enumerate(tqdm(all_prompts, desc=\"Processing\", unit=\"query\")):\n",
    "    round_answers = []\n",
    "    round_predictions = []\n",
    "    for prompt in prompts:\n",
    "        payload = {\n",
    "            \"model\": \"gpt-3.5-turbo\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            query_start = time.time()  \n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            query_time = time.time() - query_start  \n",
    "            total_api_time += query_time \n",
    "\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                generated_text = result['choices'][0]['message']['content'].strip()\n",
    "                round_answers.append(generated_text)\n",
    "                processed_pred = generated_text.lower().translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "\n",
    "                if \"yes\" in processed_pred:\n",
    "                    round_predictions.append(1)\n",
    "                elif \"no\" in processed_pred:\n",
    "                    round_predictions.append(0)\n",
    "                else:\n",
    "                    round_predictions.append(0) \n",
    "\n",
    "            else:\n",
    "                round_answers.append(\"error\")\n",
    "                round_predictions.append(0)\n",
    "\n",
    "        except Exception as e:\n",
    "            round_answers.append(\"error\")\n",
    "            round_predictions.append(0)\n",
    "\n",
    "    if sum(round_predictions) > len(round_predictions) / 2:\n",
    "        final_prediction = 1\n",
    "    else:\n",
    "        final_prediction = 0\n",
    "\n",
    "    predictions.append(final_prediction)\n",
    "    answers.append(round_answers)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "average_api_time = total_api_time / (len(all_prompts) * len(prompts)) if len(all_prompts) > 0 else 0\n",
    "\n",
    "precision = precision_score(truth_labels, predictions, zero_division=1)\n",
    "recall = recall_score(truth_labels, predictions, zero_division=1)\n",
    "f1 = f1_score(truth_labels, predictions, zero_division=1)\n",
    "accuracy = accuracy_score(truth_labels, predictions)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Total Time: {total_time:.2f} seconds\")\n",
    "print(f\"Average API Query Time: {average_api_time:.2f} seconds per query\")\n",
    "\n",
    "results = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1,\n",
    "    \"Total Time (s)\": total_time,\n",
    "    \"Average API Query Time (s/query)\": average_api_time\n",
    "}\n",
    "\n",
    "output_dir = \"output_results-gpt3.5-self-consistency\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{output_dir}/results.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile, indent=2)\n",
    "\n",
    "with open(f\"{output_dir}/answers.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(answers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f\"{output_dir}/prompts.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(all_prompts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f07f30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
