{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd9e34-d83e-45c0-ba06-740c9d09ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed321bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataset/network/table.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def generate_partitions(data):\n",
    "    \"\"\"\n",
    "    Generate partition sets based on predefined rules.\n",
    "    initial Rules:\n",
    "    1. Same 'name' -> group entities into the same block.\n",
    "    2. Same 'phone' -> group entities into the same block.\n",
    "    3. Same 'type' -> group entities into the same block.\n",
    "    Each rule generates a set of partition blocks, where entities in each block are represented as tuples.\n",
    "\n",
    "    \"\"\"\n",
    "    partitions = {}  \n",
    "    for rule_id, column in enumerate(['name', 'phone', 'type'], start=1):\n",
    "        grouped = data.groupby(column)  \n",
    "        blocks = []  \n",
    "        for group_key, group in grouped:\n",
    "            if len(group) > 1:  \n",
    "                block = list(group['id'])  \n",
    "                blocks.append(block)\n",
    "        partitions[f\"Rule_{rule_id}_{column}\"] = blocks  \n",
    "    return partitions\n",
    "\n",
    "\n",
    "partitions = generate_partitions(data)\n",
    "\n",
    "\n",
    "total_partitions = len(partitions)\n",
    "initial_probabilities = {partition: 1 / total_partitions for partition in partitions}\n",
    "\n",
    "\n",
    "csv_data = []\n",
    "for partition, blocks in partitions.items():\n",
    "    \n",
    "    unique_pairs = set()\n",
    "   \n",
    "    for block in blocks:\n",
    "        if len(block) > 1:\n",
    "            \n",
    "            for pair in itertools.combinations(sorted(block), 2):\n",
    "                unique_pairs.add(pair)\n",
    "\n",
    "    combined_blocks = '; '.join([f\"({i},{j})\" for i, j in sorted(unique_pairs)])\n",
    "    \n",
    "    csv_data.append({\n",
    "        \"Partition\": partition,\n",
    "        \"Blocks\": combined_blocks,\n",
    "        \"Probability\": initial_probabilities[partition]\n",
    "    })\n",
    "\n",
    "csv_df = pd.DataFrame(csv_data)\n",
    "\n",
    "output_csv_file = \"initial_partitions_combined.csv\"\n",
    "csv_df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6933e46b-e73b-41fb-8178-63c62fd44d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'initial_partitions_combined.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "probabilities = df['Probability']\n",
    "\n",
    "entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "print(f\"entropy: {entropy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "714e1870-9cc0-4e80-a580-76b6775a3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'initial_partitions_combined.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "ground_truth_pairs = set()\n",
    "\n",
    "with open('dataset/ground_truth_fodors_zagats.txt', 'r') as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]  \n",
    "    for i in range(0, len(lines), 2):  \n",
    "        pair = (int(lines[i]), int(lines[i + 1]))\n",
    "        ground_truth_pairs.add(pair)\n",
    "\n",
    "\n",
    "print(\"Parsed ground truth pairs:\")\n",
    "print(ground_truth_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd175cfc-d1f1-4356-8743-3604ec1a0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_blocks(blocks):\n",
    "    matches = re.findall(r'\\((\\d+,\\s?\\d+)\\)', blocks)\n",
    "    return [tuple(map(int, match.split(','))) for match in matches]\n",
    "\n",
    "df[\"parsed_blocks\"] = df[\"Blocks\"].apply(parse_blocks)\n",
    "\n",
    "def calculate_dispute_score(match, df):\n",
    "    \"\"\"S(MQ_i)\"\"\"\n",
    "    probabilities = df[df[\"parsed_blocks\"].apply(lambda blocks: match in blocks)][\"Probability\"]\n",
    "    total_probability = probabilities.sum()\n",
    "    score = 1 / (1 + abs(total_probability - 0.5))  \n",
    "    return score\n",
    "\n",
    "llm_confidence = 0.9\n",
    "\n",
    "results = []\n",
    "\n",
    "all_matches = set(match for blocks in df[\"parsed_blocks\"] for match in blocks)\n",
    "count=0\n",
    "for match in all_matches:\n",
    "    score = calculate_dispute_score(match, df)\n",
    "    if score > 0.8: \n",
    "        results.append({\"Match\": match, \"Dispute_Score\": score})\n",
    "        count+=1\n",
    "        if(count==100):\n",
    "            break\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4d81fc75-2536-4114-ac80-a9a1323bc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_probability(initial_prob, match_prob, correct_prob, case):\n",
    "    \"\"\"\n",
    "    Adjust partition probabilities using Bayes' theorem.\n",
    "    initial_prob: Initial probability P(P_i)\n",
    "    match_prob: Initial probability of a match pair P(m)\n",
    "    correct_prob: Correctness probability given by the LLM P(Θ)\n",
    "    case: Scenario (1–4) determining the choice of formula\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if case == 1:\n",
    "        numerator = initial_prob * correct_prob\n",
    "        denominator = (match_prob * correct_prob) + ((1 - match_prob) * (1 - correct_prob))\n",
    "        updated_prob = numerator / denominator\n",
    "        \n",
    "    elif case == 2:\n",
    "        numerator = initial_prob * (1 - correct_prob)\n",
    "        denominator = (match_prob * correct_prob) + ((1 - match_prob) * (1 - correct_prob))\n",
    "        updated_prob = numerator / denominator\n",
    "        \n",
    "    elif case == 3:\n",
    "        numerator = initial_prob * (1 - correct_prob)\n",
    "        denominator = (match_prob * (1 - correct_prob)) + ((1 - match_prob) * correct_prob)\n",
    "        updated_prob = numerator / denominator\n",
    "        \n",
    "    elif case == 4:\n",
    "        numerator = initial_prob * correct_prob\n",
    "        denominator = (match_prob * (1 - correct_prob)) + ((1 - match_prob) * correct_prob)\n",
    "        updated_prob = numerator / denominator\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid case specified.\")\n",
    "    \n",
    "    if denominator == 0:\n",
    "        raise ZeroDivisionError(\"Denominator is zero, cannot update probability.\")\n",
    "\n",
    "    return updated_prob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adjust_partition_probabilities(df, correct_prob=0.9):\n",
    "    partition_states = {\n",
    "        row['Partition']: {\n",
    "            \"Blocks\": row['parsed_blocks'].copy(),\n",
    "            \"Probability\": row['Probability']\n",
    "        } for _, row in df.iterrows()\n",
    "    }\n",
    "\n",
    "    for _, result in results_df.iterrows():\n",
    "        match = result['Match'] \n",
    "        is_correct = match in ground_truth_pairs \n",
    "        print(f\"Processing match: {match}, Is Correct: {is_correct}\")\n",
    "        match_prob = sum(state['Probability'] for state in partition_states.values()\n",
    "                         if match in state['Blocks'])  \n",
    "\n",
    "        for partition, state in partition_states.items():\n",
    "            blocks = state['Blocks']\n",
    "            initial_prob = state['Probability']\n",
    "\n",
    "            in_block = match in blocks\n",
    "            updated_prob = initial_prob  \n",
    "            \n",
    "          \n",
    "            if is_correct and in_block:\n",
    "                updated_prob = update_probability(initial_prob, match_prob, correct_prob, 1)\n",
    "            elif is_correct and not in_block:\n",
    "                updated_prob = update_probability(initial_prob, match_prob, correct_prob, 2)\n",
    "            elif not is_correct and in_block:\n",
    "                updated_prob = update_probability(initial_prob, match_prob, correct_prob, 3)\n",
    "\n",
    "            else:\n",
    "                updated_prob = update_probability(initial_prob, match_prob, correct_prob, 4)\n",
    "     \n",
    "          \n",
    "            if is_correct and not in_block:\n",
    "                blocks.append(match)\n",
    "            elif not is_correct and in_block:\n",
    "                blocks.remove(match)\n",
    "\n",
    "            state['Probability'] = updated_prob\n",
    "            state['Blocks'] = blocks.copy()  \n",
    "\n",
    "    updated_partitions = [\n",
    "        {\"Partition\": partition, \"Updated_Blocks\": state['Blocks'], \"Updated_Probability\": state['Probability']}\n",
    "        for partition, state in partition_states.items()\n",
    "    ]\n",
    "\n",
    "    return updated_partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c085c4f-2b3e-4ffa-b7f6-c37e9d90e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "updated_partitions = adjust_partition_probabilities(df)\n",
    "\n",
    "updated_results = []\n",
    "for partition_data in updated_partitions:\n",
    "    partition = partition_data[\"Partition\"]\n",
    "    updated_blocks = partition_data[\"Updated_Blocks\"]\n",
    "    updated_probability = partition_data.get(\"Updated_Probability\", 0.64)\n",
    "\n",
    "    combined_blocks = '; '.join(\n",
    "        ['(' + ','.join(map(str, block)) + ')' for block in updated_blocks]\n",
    "    )\n",
    "    \n",
    "    updated_results.append({\n",
    "        \"Partition\": partition,\n",
    "        \"Blocks\": combined_blocks,\n",
    "        \"Probability\": updated_probability\n",
    "    })\n",
    "\n",
    "updated_df = pd.DataFrame(updated_results)\n",
    "\n",
    "updated_file_path = 'updated_partitions_combined.csv'\n",
    "updated_df.to_csv(updated_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
